{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Please use HDF reader for matlab v7.3 files, e.g. h5py",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msio\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 读取.mat文件\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m mat_data \u001b[38;5;241m=\u001b[39m \u001b[43msio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadmat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mD:/BaiduNetdiskDownload/UAV_Fault_Dataset/Train/MF1/MF1_1.mat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# # 提取变量\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# matrix1 = mat_data['matrix1']\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# matrix2 = mat_data['matrix2']\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# print(\"matrix1的形状:\", matrix1.shape)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# print(\"matrix2的数据类型:\", type(matrix2))\u001b[39;00m\n",
      "File \u001b[1;32md:\\Program\\Anaconda\\envs\\DL\\lib\\site-packages\\scipy\\io\\matlab\\_mio.py:226\u001b[0m, in \u001b[0;36mloadmat\u001b[1;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m    224\u001b[0m variable_names \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariable_names\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m--> 226\u001b[0m     MR, _ \u001b[38;5;241m=\u001b[39m mat_reader_factory(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    227\u001b[0m     matfile_dict \u001b[38;5;241m=\u001b[39m MR\u001b[38;5;241m.\u001b[39mget_variables(variable_names)\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mdict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Program\\Anaconda\\envs\\DL\\lib\\site-packages\\scipy\\io\\matlab\\_mio.py:80\u001b[0m, in \u001b[0;36mmat_reader_factory\u001b[1;34m(file_name, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m MatFile5Reader(byte_stream, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), file_opened\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mjv \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m---> 80\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease use HDF reader for matlab v7.3 \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     81\u001b[0m                               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiles, e.g. h5py\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDid not recognize version \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m mjv)\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Please use HDF reader for matlab v7.3 files, e.g. h5py"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "\n",
    "# 读取.mat文件\n",
    "mat_data = sio.loadmat('D:/BaiduNetdiskDownload/UAV_Fault_Dataset/Train/MF1/MF1_1.mat')\n",
    "\n",
    "# # 提取变量\n",
    "# matrix1 = mat_data['matrix1']\n",
    "# matrix2 = mat_data['matrix2']\n",
    "\n",
    "# # 显示变量信息\n",
    "# print(\"matrix1的形状:\", matrix1.shape)\n",
    "# print(\"matrix2的数据类型:\", type(matrix2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdf5storage\n",
    "import torch\n",
    "import torch.functional as F\n",
    "path = 'D:/BaiduNetdiskDownload/UAV_Fault_Dataset/Train/MF1/MF1_3.mat'\n",
    "data = hdf5storage.loadmat(path)['single_data']\n",
    "# value= data.values().to(tensor)\n",
    "# value.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy.ndarray  torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.reshape(-1)\n",
    "F.pad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "data = transforms.ToTensor()(data)\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16000])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.7848, dtype=torch.float64), tensor(0.7583, dtype=torch.float64))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.min(),data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=1000):\n",
    "        #-----------------------------------#\n",
    "        #   假设输入进来的图片是600,600,3\n",
    "        #-----------------------------------#\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        # 600,600,3 -> 300,300,64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # 300,300,64 -> 150,150,64\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=0, ceil_mode=True)\n",
    "\n",
    "        # 150,150,64 -> 150,150,256\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        # 150,150,256 -> 75,75,512\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        # 75,75,512 -> 38,38,1024 到这里可以获得一个38,38,1024的共享特征层\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        # self.layer4被用在classifier模型中\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AvgPool2d(7)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        #-------------------------------------------------------------------#\n",
    "        #   当模型需要进行高和宽的压缩的时候，就需要用到残差边的downsample\n",
    "        #-------------------------------------------------------------------#\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def resnet50(pretrained = False):\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3])\n",
    "    \n",
    "    #----------------------------------------------------------------------------#\n",
    "    #   获取特征提取部分，从conv1到model.layer3，最终获得一个38,38,1024的特征层\n",
    "    #----------------------------------------------------------------------------#\n",
    "    features    = list([model.conv1, model.bn1, model.relu, model.maxpool, model.layer1, model.layer2, model.layer3])\n",
    "    #----------------------------------------------------------------------------#\n",
    "    #   获取分类部分，从model.layer4到model.avgpool\n",
    "    #----------------------------------------------------------------------------#\n",
    "    classifier  = list([model.layer4, model.avgpool])\n",
    "    \n",
    "    features    = nn.Sequential(*features)\n",
    "    classifier  = nn.Sequential(*classifier)\n",
    "    return features, classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(Bottleneck, [3, 4, 6, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.randn(1,3,600,600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x8192 and 2048x1000)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 109\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    107\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[0;32m    108\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 109\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32md:\\Program\\Anaconda\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Program\\Anaconda\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x8192 and 2048x1000)"
     ]
    }
   ],
   "source": [
    "model.forward(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegionProposalNetwork(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_channels     = 512, \n",
    "        mid_channels    = 512, \n",
    "        ratios          = [0.5, 1, 2],\n",
    "        anchor_scales   = [8, 16, 32], \n",
    "        feat_stride     = 16,\n",
    "        mode            = \"training\",\n",
    "    ):\n",
    "        super(RegionProposalNetwork, self).__init__()\n",
    "        #-----------------------------------------#\n",
    "        #   生成基础先验框，shape为[9, 4]\n",
    "        #-----------------------------------------#\n",
    "        self.anchor_base    = generate_anchor_base(anchor_scales = anchor_scales, ratios = ratios)\n",
    "        n_anchor            = self.anchor_base.shape[0]\n",
    "\n",
    "        #-----------------------------------------#\n",
    "        #   先进行一个3x3的卷积，可理解为特征整合\n",
    "        #-----------------------------------------#\n",
    "        self.conv1  = nn.Conv2d(in_channels, mid_channels, 3, 1, 1)\n",
    "        #-----------------------------------------#\n",
    "        #   分类预测先验框内部是否包含物体\n",
    "        #-----------------------------------------#\n",
    "        self.score  = nn.Conv2d(mid_channels, n_anchor * 2, 1, 1, 0)\n",
    "        #-----------------------------------------#\n",
    "        #   回归预测对先验框进行调整\n",
    "        #-----------------------------------------#\n",
    "        self.loc    = nn.Conv2d(mid_channels, n_anchor * 4, 1, 1, 0)\n",
    "\n",
    "        #-----------------------------------------#\n",
    "        #   特征点间距步长\n",
    "        #-----------------------------------------#\n",
    "        self.feat_stride    = feat_stride\n",
    "        #-----------------------------------------#\n",
    "        #   用于对建议框解码并进行非极大抑制\n",
    "        #-----------------------------------------#\n",
    "        self.proposal_layer = ProposalCreator(mode)\n",
    "        #--------------------------------------#\n",
    "        #   对FPN的网络部分进行权值初始化\n",
    "        #--------------------------------------#\n",
    "        normal_init(self.conv1, 0, 0.01)\n",
    "        normal_init(self.score, 0, 0.01)\n",
    "        normal_init(self.loc, 0, 0.01)\n",
    "\n",
    "    def forward(self, x, img_size, scale=1.):\n",
    "        n, _, h, w = x.shape\n",
    "        #-----------------------------------------#\n",
    "        #   先进行一个3x3的卷积，可理解为特征整合\n",
    "        #-----------------------------------------#\n",
    "        x = F.relu(self.conv1(x))\n",
    "        #-----------------------------------------#\n",
    "        #   回归预测对先验框进行调整\n",
    "        #-----------------------------------------#\n",
    "        rpn_locs = self.loc(x)\n",
    "        rpn_locs = rpn_locs.permute(0, 2, 3, 1).contiguous().view(n, -1, 4)\n",
    "        #-----------------------------------------#\n",
    "        #   分类预测先验框内部是否包含物体\n",
    "        #-----------------------------------------#\n",
    "        rpn_scores = self.score(x)\n",
    "        rpn_scores = rpn_scores.permute(0, 2, 3, 1).contiguous().view(n, -1, 2)\n",
    "        \n",
    "        #--------------------------------------------------------------------------------------#\n",
    "        #   进行softmax概率计算，每个先验框只有两个判别结果\n",
    "        #   内部包含物体或者内部不包含物体，rpn_softmax_scores[:, :, 1]的内容为包含物体的概率\n",
    "        #--------------------------------------------------------------------------------------#\n",
    "        rpn_softmax_scores  = F.softmax(rpn_scores, dim=-1)\n",
    "        rpn_fg_scores       = rpn_softmax_scores[:, :, 1].contiguous()\n",
    "        rpn_fg_scores       = rpn_fg_scores.view(n, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProposalCreator():\n",
    "    def __init__(\n",
    "        self, \n",
    "        mode, \n",
    "        nms_iou             = 0.7,\n",
    "        n_train_pre_nms     = 12000,\n",
    "        n_train_post_nms    = 600,\n",
    "        n_test_pre_nms      = 3000,\n",
    "        n_test_post_nms     = 300,\n",
    "        min_size            = 16\n",
    "    \n",
    "    ):\n",
    "        #-----------------------------------#\n",
    "        #   设置预测还是训练\n",
    "        #-----------------------------------#\n",
    "        self.mode               = mode\n",
    "        #-----------------------------------#\n",
    "        #   建议框非极大抑制的iou大小\n",
    "        #-----------------------------------#\n",
    "        self.nms_iou            = nms_iou\n",
    "        #-----------------------------------#\n",
    "        #   训练用到的建议框数量\n",
    "        #-----------------------------------#\n",
    "        self.n_train_pre_nms    = n_train_pre_nms\n",
    "        self.n_train_post_nms   = n_train_post_nms\n",
    "        #-----------------------------------#\n",
    "        #   预测用到的建议框数量\n",
    "        #-----------------------------------#\n",
    "        self.n_test_pre_nms     = n_test_pre_nms\n",
    "        self.n_test_post_nms    = n_test_post_nms\n",
    "        self.min_size           = min_size\n",
    "\n",
    "    def __call__(self, loc, score, anchor, img_size, scale=1.):\n",
    "        if self.mode == \"training\":\n",
    "            n_pre_nms   = self.n_train_pre_nms\n",
    "            n_post_nms  = self.n_train_post_nms\n",
    "        else:\n",
    "            n_pre_nms   = self.n_test_pre_nms\n",
    "            n_post_nms  = self.n_test_post_nms\n",
    "\n",
    "        #-----------------------------------#\n",
    "        #   将先验框转换成tensor\n",
    "        #-----------------------------------#\n",
    "        anchor = torch.from_numpy(anchor)\n",
    "        if loc.is_cuda:\n",
    "            anchor = anchor.cuda()\n",
    "        #-----------------------------------#\n",
    "        #   将RPN网络预测结果转化成建议框\n",
    "        #-----------------------------------#\n",
    "        roi = loc2bbox(anchor, loc)\n",
    "        #-----------------------------------#\n",
    "        #   防止建议框超出图像边缘\n",
    "        #-----------------------------------#\n",
    "        roi[:, [0, 2]] = torch.clamp(roi[:, [0, 2]], min = 0, max = img_size[1])\n",
    "        roi[:, [1, 3]] = torch.clamp(roi[:, [1, 3]], min = 0, max = img_size[0])\n",
    "        \n",
    "        #-----------------------------------#\n",
    "        #   建议框的宽高的最小值不可以小于16\n",
    "        #-----------------------------------#\n",
    "        min_size    = self.min_size * scale\n",
    "        keep        = torch.where(((roi[:, 2] - roi[:, 0]) >= min_size) & ((roi[:, 3] - roi[:, 1]) >= min_size))[0]\n",
    "        #-----------------------------------#\n",
    "        #   将对应的建议框保留下来\n",
    "        #-----------------------------------#\n",
    "        roi         = roi[keep, :]\n",
    "        score       = score[keep]\n",
    "\n",
    "        #-----------------------------------#\n",
    "        #   根据得分进行排序，取出建议框\n",
    "        #-----------------------------------#\n",
    "        order       = torch.argsort(score, descending=True)\n",
    "        if n_pre_nms > 0:\n",
    "            order   = order[:n_pre_nms]\n",
    "        roi     = roi[order, :]\n",
    "        score   = score[order]\n",
    "\n",
    "        #-----------------------------------#\n",
    "        #   对建议框进行非极大抑制\n",
    "        #   使用官方的非极大抑制会快非常多\n",
    "        #-----------------------------------#\n",
    "        keep    = nms(roi, score, self.nms_iou)\n",
    "        keep    = keep[:n_post_nms]\n",
    "        roi     = roi[keep]\n",
    "        return roi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet50RoIHead(nn.Module):\n",
    "    def __init__(self, n_class, roi_size, spatial_scale, classifier):\n",
    "        super(Resnet50RoIHead, self).__init__()\n",
    "        self.classifier = classifier\n",
    "        #--------------------------------------#\n",
    "        #   对ROIPooling后的的结果进行回归预测\n",
    "        #--------------------------------------#\n",
    "        self.cls_loc = nn.Linear(2048, n_class * 4)\n",
    "        #-----------------------------------#\n",
    "        #   对ROIPooling后的的结果进行分类\n",
    "        #-----------------------------------#\n",
    "        self.score = nn.Linear(2048, n_class)\n",
    "        #-----------------------------------#\n",
    "        #   权值初始化\n",
    "        #-----------------------------------#\n",
    "        normal_init(self.cls_loc, 0, 0.001)\n",
    "        normal_init(self.score, 0, 0.01)\n",
    "\n",
    "        self.roi = RoIPool((roi_size, roi_size), spatial_scale)\n",
    "\n",
    "    def forward(self, x, rois, roi_indices, img_size):\n",
    "        n, _, _, _ = x.shape\n",
    "        if x.is_cuda:\n",
    "            roi_indices = roi_indices.cuda()\n",
    "            rois = rois.cuda()\n",
    "        \n",
    "        rois_feature_map = torch.zeros_like(rois)\n",
    "        rois_feature_map[:, [0,2]] = rois[:, [0,2]] / img_size[1] * x.size()[3]\n",
    "        rois_feature_map[:, [1,3]] = rois[:, [1,3]] / img_size[0] * x.size()[2]\n",
    "\n",
    "        indices_and_rois = torch.cat([roi_indices[:, None], rois_feature_map], dim=1)\n",
    "        #-----------------------------------#\n",
    "        #   利用建议框对公用特征层进行截取\n",
    "        #-----------------------------------#\n",
    "        pool = self.roi(x, indices_and_rois)\n",
    "        #-----------------------------------#\n",
    "        #   利用classifier网络进行特征提取\n",
    "        #-----------------------------------#\n",
    "        fc7 = self.classifier(pool)\n",
    "        #--------------------------------------------------------------#\n",
    "        #   当输入为一张图片的时候，这里获得的f7的shape为[300, 2048]\n",
    "        #--------------------------------------------------------------#\n",
    "        fc7 = fc7.view(fc7.size(0), -1)\n",
    "\n",
    "        roi_cls_locs    = self.cls_loc(fc7)\n",
    "        roi_scores      = self.score(fc7)\n",
    "        roi_cls_locs    = roi_cls_locs.view(n, -1, roi_cls_locs.size(1))\n",
    "        roi_scores      = roi_scores.view(n, -1, roi_scores.size(1))\n",
    "        return roi_cls_locs, roi_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_iou(bbox_a, bbox_b):\n",
    "    if bbox_a.shape[1] != 4 or bbox_b.shape[1] != 4:\n",
    "        print(bbox_a, bbox_b)\n",
    "        raise IndexError\n",
    "    tl = np.maximum(bbox_a[:, None, :2], bbox_b[:, :2])\n",
    "    br = np.minimum(bbox_a[:, None, 2:], bbox_b[:, 2:])\n",
    "    area_i = np.prod(br - tl, axis=2) * (tl < br).all(axis=2)\n",
    "    area_a = np.prod(bbox_a[:, 2:] - bbox_a[:, :2], axis=1)\n",
    "    area_b = np.prod(bbox_b[:, 2:] - bbox_b[:, :2], axis=1)\n",
    "    return area_i / (area_a[:, None] + area_b - area_i)\n",
    "\n",
    "def bbox2loc(src_bbox, dst_bbox):\n",
    "    width = src_bbox[:, 2] - src_bbox[:, 0]\n",
    "    height = src_bbox[:, 3] - src_bbox[:, 1]\n",
    "    ctr_x = src_bbox[:, 0] + 0.5 * width\n",
    "    ctr_y = src_bbox[:, 1] + 0.5 * height\n",
    "\n",
    "    base_width = dst_bbox[:, 2] - dst_bbox[:, 0]\n",
    "    base_height = dst_bbox[:, 3] - dst_bbox[:, 1]\n",
    "    base_ctr_x = dst_bbox[:, 0] + 0.5 * base_width\n",
    "    base_ctr_y = dst_bbox[:, 1] + 0.5 * base_height\n",
    "\n",
    "    eps = np.finfo(height.dtype).eps\n",
    "    width = np.maximum(width, eps)\n",
    "    height = np.maximum(height, eps)\n",
    "\n",
    "    dx = (base_ctr_x - ctr_x) / width\n",
    "    dy = (base_ctr_y - ctr_y) / height\n",
    "    dw = np.log(base_width / width)\n",
    "    dh = np.log(base_height / height)\n",
    "\n",
    "    loc = np.vstack((dx, dy, dw, dh)).transpose()\n",
    "    return loc\n",
    "\n",
    "class AnchorTargetCreator(object):\n",
    "    def __init__(self, n_sample=256, pos_iou_thresh=0.7, neg_iou_thresh=0.3, pos_ratio=0.5):\n",
    "        self.n_sample       = n_sample\n",
    "        self.pos_iou_thresh = pos_iou_thresh\n",
    "        self.neg_iou_thresh = neg_iou_thresh\n",
    "        self.pos_ratio      = pos_ratio\n",
    "\n",
    "    def __call__(self, bbox, anchor):\n",
    "        argmax_ious, label = self._create_label(anchor, bbox)\n",
    "        if (label > 0).any():\n",
    "            loc = bbox2loc(anchor, bbox[argmax_ious])\n",
    "            return loc, label\n",
    "        else:\n",
    "            return np.zeros_like(anchor), label\n",
    "\n",
    "    def _calc_ious(self, anchor, bbox):\n",
    "        #----------------------------------------------#\n",
    "        #   anchor和bbox的iou\n",
    "        #   获得的ious的shape为[num_anchors, num_gt]\n",
    "        #----------------------------------------------#\n",
    "        ious = bbox_iou(anchor, bbox)\n",
    "\n",
    "        if len(bbox)==0:\n",
    "            return np.zeros(len(anchor), np.int32), np.zeros(len(anchor)), np.zeros(len(bbox))\n",
    "        #---------------------------------------------------------#\n",
    "        #   获得每一个先验框最对应的真实框  [num_anchors, ]\n",
    "        #---------------------------------------------------------#\n",
    "        argmax_ious = ious.argmax(axis=1)\n",
    "        #---------------------------------------------------------#\n",
    "        #   找出每一个先验框最对应的真实框的iou  [num_anchors, ]\n",
    "        #---------------------------------------------------------#\n",
    "        max_ious = np.max(ious, axis=1)\n",
    "        #---------------------------------------------------------#\n",
    "        #   获得每一个真实框最对应的先验框  [num_gt, ]\n",
    "        #---------------------------------------------------------#\n",
    "        gt_argmax_ious = ious.argmax(axis=0)\n",
    "        #---------------------------------------------------------#\n",
    "        #   保证每一个真实框都存在对应的先验框\n",
    "        #---------------------------------------------------------#\n",
    "        for i in range(len(gt_argmax_ious)):\n",
    "            argmax_ious[gt_argmax_ious[i]] = i\n",
    "\n",
    "        return argmax_ious, max_ious, gt_argmax_ious\n",
    "        \n",
    "    def _create_label(self, anchor, bbox):\n",
    "        # ------------------------------------------ #\n",
    "        #   1是正样本，0是负样本，-1忽略\n",
    "        #   初始化的时候全部设置为-1\n",
    "        # ------------------------------------------ #\n",
    "        label = np.empty((len(anchor),), dtype=np.int32)\n",
    "        label.fill(-1)\n",
    "\n",
    "        # ------------------------------------------------------------------------ #\n",
    "        #   argmax_ious为每个先验框对应的最大的真实框的序号         [num_anchors, ]\n",
    "        #   max_ious为每个真实框对应的最大的真实框的iou             [num_anchors, ]\n",
    "        #   gt_argmax_ious为每一个真实框对应的最大的先验框的序号    [num_gt, ]\n",
    "        # ------------------------------------------------------------------------ #\n",
    "        argmax_ious, max_ious, gt_argmax_ious = self._calc_ious(anchor, bbox)\n",
    "        \n",
    "        # ----------------------------------------------------- #\n",
    "        #   如果小于门限值则设置为负样本\n",
    "        #   如果大于门限值则设置为正样本\n",
    "        #   每个真实框至少对应一个先验框\n",
    "        # ----------------------------------------------------- #\n",
    "        label[max_ious < self.neg_iou_thresh] = 0\n",
    "        label[max_ious >= self.pos_iou_thresh] = 1\n",
    "        if len(gt_argmax_ious)>0:\n",
    "            label[gt_argmax_ious] = 1\n",
    "\n",
    "        # ----------------------------------------------------- #\n",
    "        #   判断正样本数量是否大于128，如果大于则限制在128\n",
    "        # ----------------------------------------------------- #\n",
    "        n_pos = int(self.pos_ratio * self.n_sample)\n",
    "        pos_index = np.where(label == 1)[0]\n",
    "        if len(pos_index) > n_pos:\n",
    "            disable_index = np.random.choice(pos_index, size=(len(pos_index) - n_pos), replace=False)\n",
    "            label[disable_index] = -1\n",
    "\n",
    "        # ----------------------------------------------------- #\n",
    "        #   平衡正负样本，保持总数量为256\n",
    "        # ----------------------------------------------------- #\n",
    "        n_neg = self.n_sample - np.sum(label == 1)\n",
    "        neg_index = np.where(label == 0)[0]\n",
    "        if len(neg_index) > n_neg:\n",
    "            disable_index = np.random.choice(neg_index, size=(len(neg_index) - n_neg), replace=False)\n",
    "            label[disable_index] = -1\n",
    "\n",
    "        return argmax_ious, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProposalTargetCreator(object):\n",
    "    def __init__(self, n_sample=128, pos_ratio=0.5, pos_iou_thresh=0.5, neg_iou_thresh_high=0.5, neg_iou_thresh_low=0):\n",
    "        self.n_sample = n_sample\n",
    "        self.pos_ratio = pos_ratio\n",
    "        self.pos_roi_per_image = np.round(self.n_sample * self.pos_ratio)\n",
    "        self.pos_iou_thresh = pos_iou_thresh\n",
    "        self.neg_iou_thresh_high = neg_iou_thresh_high\n",
    "        self.neg_iou_thresh_low = neg_iou_thresh_low\n",
    "\n",
    "    def __call__(self, roi, bbox, label, loc_normalize_std=(0.1, 0.1, 0.2, 0.2)):\n",
    "        roi = np.concatenate((roi.detach().cpu().numpy(), bbox), axis=0)\n",
    "        # ----------------------------------------------------- #\n",
    "        #   计算建议框和真实框的重合程度\n",
    "        # ----------------------------------------------------- #\n",
    "        iou = bbox_iou(roi, bbox)\n",
    "        \n",
    "        if len(bbox)==0:\n",
    "            gt_assignment = np.zeros(len(roi), np.int32)\n",
    "            max_iou = np.zeros(len(roi))\n",
    "            gt_roi_label = np.zeros(len(roi))\n",
    "        else:\n",
    "            #---------------------------------------------------------#\n",
    "            #   获得每一个建议框最对应的真实框  [num_roi, ]\n",
    "            #---------------------------------------------------------#\n",
    "            gt_assignment = iou.argmax(axis=1)\n",
    "            #---------------------------------------------------------#\n",
    "            #   获得每一个建议框最对应的真实框的iou  [num_roi, ]\n",
    "            #---------------------------------------------------------#\n",
    "            max_iou = iou.max(axis=1)\n",
    "            #---------------------------------------------------------#\n",
    "            #   真实框的标签要+1因为有背景的存在\n",
    "            #---------------------------------------------------------#\n",
    "            gt_roi_label = label[gt_assignment] + 1\n",
    "\n",
    "        #----------------------------------------------------------------#\n",
    "        #   满足建议框和真实框重合程度大于neg_iou_thresh_high的作为负样本\n",
    "        #   将正样本的数量限制在self.pos_roi_per_image以内\n",
    "        #----------------------------------------------------------------#\n",
    "        pos_index = np.where(max_iou >= self.pos_iou_thresh)[0]\n",
    "        pos_roi_per_this_image = int(min(self.pos_roi_per_image, pos_index.size))\n",
    "        if pos_index.size > 0:\n",
    "            pos_index = np.random.choice(pos_index, size=pos_roi_per_this_image, replace=False)\n",
    "\n",
    "        #-----------------------------------------------------------------------------------------------------#\n",
    "        #   满足建议框和真实框重合程度小于neg_iou_thresh_high大于neg_iou_thresh_low作为负样本\n",
    "        #   将正样本的数量和负样本的数量的总和固定成self.n_sample\n",
    "        #-----------------------------------------------------------------------------------------------------#\n",
    "        neg_index = np.where((max_iou < self.neg_iou_thresh_high) & (max_iou >= self.neg_iou_thresh_low))[0]\n",
    "        neg_roi_per_this_image = self.n_sample - pos_roi_per_this_image\n",
    "        neg_roi_per_this_image = int(min(neg_roi_per_this_image, neg_index.size))\n",
    "        if neg_index.size > 0:\n",
    "            neg_index = np.random.choice(neg_index, size=neg_roi_per_this_image, replace=False)\n",
    "            \n",
    "        #---------------------------------------------------------#\n",
    "        #   sample_roi      [n_sample, ]\n",
    "        #   gt_roi_loc      [n_sample, 4]\n",
    "        #   gt_roi_label    [n_sample, ]\n",
    "        #---------------------------------------------------------#\n",
    "        keep_index = np.append(pos_index, neg_index)\n",
    "\n",
    "        sample_roi = roi[keep_index]\n",
    "        if len(bbox)==0:\n",
    "            return sample_roi, np.zeros_like(sample_roi), gt_roi_label[keep_index]\n",
    "\n",
    "        gt_roi_loc = bbox2loc(sample_roi, bbox[gt_assignment[keep_index]])\n",
    "        gt_roi_loc = (gt_roi_loc / np.array(loc_normalize_std, np.float32))\n",
    "\n",
    "        gt_roi_label = gt_roi_label[keep_index]\n",
    "        gt_roi_label[pos_roi_per_this_image:] = 0\n",
    "        return sample_roi, gt_roi_loc, gt_roi_label\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
