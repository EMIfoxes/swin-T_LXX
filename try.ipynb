{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "\n",
    "from my_dataset import MyDataSet_1\n",
    "from data_set import CustomCWRUDataset,CWRU\n",
    "from model import swin_tiny_patch4_window7_224 as create_model\n",
    "from utils import read_split_data, train_one_epoch, evaluate\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    device = torch.device(args.device if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    if os.path.exists(\"./weights\") is False:\n",
    "        os.makedirs(\"./weights\")\n",
    "\n",
    "    tb_writer = SummaryWriter()\n",
    "\n",
    "    data_1 = CWRU(root_dir=args.data_path)\n",
    "\n",
    "    train_dataset, val_dataset = data_1.train_test_split_order()\n",
    "    \n",
    "    batch_size = args.batch_size\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers\n",
    "    print('Using {} dataloader workers every process'.format(nw))\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True,\n",
    "                                               pin_memory=True,\n",
    "                                               num_workers=nw,\n",
    "                                               )\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=False,\n",
    "                                             pin_memory=True,\n",
    "                                             num_workers=nw,\n",
    "                                             )\n",
    "\n",
    "    model = create_model(num_classes=args.num_classes).to(device)\n",
    "\n",
    "    if args.weights != \"\":\n",
    "        assert os.path.exists(args.weights), \"weights file: '{}' not exist.\".format(args.weights)\n",
    "        weights_dict = torch.load(args.weights, map_location=device)[\"model\"]\n",
    "        # 删除有关分类类别的权重\n",
    "        for k in list(weights_dict.keys()):\n",
    "            if \"head\" in k:\n",
    "                del weights_dict[k]\n",
    "        print(model.load_state_dict(weights_dict, strict=False))\n",
    "\n",
    "    if args.freeze_layers:\n",
    "        for name, para in model.named_parameters():\n",
    "            # 除head外，其他权重全部冻结\n",
    "            if \"head\" not in name:\n",
    "                para.requires_grad_(False)\n",
    "            else:\n",
    "                print(\"training {}\".format(name))\n",
    "\n",
    "    pg = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = optim.AdamW(pg, lr=args.lr, weight_decay=5E-2)\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        # train\n",
    "        train_loss, train_acc = train_one_epoch(model=model,\n",
    "                                                optimizer=optimizer,\n",
    "                                                data_loader=train_loader,\n",
    "                                                device=device,\n",
    "                                                epoch=epoch)\n",
    "\n",
    "        # validate\n",
    "        val_loss, val_acc = evaluate(model=model,\n",
    "                                     data_loader=val_loader,\n",
    "                                     device=device,\n",
    "                                     epoch=epoch)\n",
    "\n",
    "        tags = [\"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\", \"learning_rate\"]\n",
    "        tb_writer.add_scalar(tags[0], train_loss, epoch)\n",
    "        tb_writer.add_scalar(tags[1], train_acc, epoch)\n",
    "        tb_writer.add_scalar(tags[2], val_loss, epoch)\n",
    "        tb_writer.add_scalar(tags[3], val_acc, epoch)\n",
    "        tb_writer.add_scalar(tags[4], optimizer.param_groups[0][\"lr\"], epoch)\n",
    "\n",
    "        torch.save(model.state_dict(), \"./weights/model-{}.pth\".format(epoch))\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "    # parser = argparse.ArgumentParser()\n",
    "    # parser.add_argument('--num_classes', type=int, default=9)\n",
    "    # parser.add_argument('--epochs', type=int, default=10)\n",
    "    # parser.add_argument('--batch-size', type=int, default=8)\n",
    "    # parser.add_argument('--lr', type=float, default=0.0008)\n",
    "\n",
    "    # # 数据集所在根目录\n",
    "    # # https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
    "    # parser.add_argument('--data-path', type=str,\n",
    "    #                     default=\"D:/BaiduNetdiskDownload/UAV_Fault_Dataset/Train\")\n",
    "\n",
    "    # # 预训练权重路径，如果不想载入就设置为空字符\n",
    "    # parser.add_argument('--weights', type=str, default='',\n",
    "    #                     help='initial weights path')\n",
    "    # # 是否冻结权重\n",
    "    # parser.add_argument('--freeze-layers', type=bool, default=False)\n",
    "    # parser.add_argument('--device', default='cuda:0', help='device id (i.e. 0 or 0,1 or cpu)')\n",
    "\n",
    "    # opt = parser.parse_args()\n",
    "\n",
    "    # main(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:/BaiduNetdiskDownload/UAV_Fault_Dataset/Train\"\n",
    "data_1 = CWRU(root_dir=path)\n",
    "\n",
    "train_dataset, val_dataset = data_1.train_test_split_order()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13629</th>\n",
       "      <td>D:/BaiduNetdiskDownload/UAV_Fault_Dataset/Trai...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61094</th>\n",
       "      <td>D:/BaiduNetdiskDownload/UAV_Fault_Dataset/Trai...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49414</th>\n",
       "      <td>D:/BaiduNetdiskDownload/UAV_Fault_Dataset/Trai...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53181</th>\n",
       "      <td>D:/BaiduNetdiskDownload/UAV_Fault_Dataset/Trai...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51001</th>\n",
       "      <td>D:/BaiduNetdiskDownload/UAV_Fault_Dataset/Trai...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8017</th>\n",
       "      <td>D:/BaiduNetdiskDownload/UAV_Fault_Dataset/Trai...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78923</th>\n",
       "      <td>D:/BaiduNetdiskDownload/UAV_Fault_Dataset/Trai...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92065</th>\n",
       "      <td>D:/BaiduNetdiskDownload/UAV_Fault_Dataset/Trai...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23442</th>\n",
       "      <td>D:/BaiduNetdiskDownload/UAV_Fault_Dataset/Trai...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43034</th>\n",
       "      <td>D:/BaiduNetdiskDownload/UAV_Fault_Dataset/Trai...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76175 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    data  label\n",
       "13629  D:/BaiduNetdiskDownload/UAV_Fault_Dataset/Trai...      2\n",
       "61094  D:/BaiduNetdiskDownload/UAV_Fault_Dataset/Trai...     10\n",
       "49414  D:/BaiduNetdiskDownload/UAV_Fault_Dataset/Trai...      8\n",
       "53181  D:/BaiduNetdiskDownload/UAV_Fault_Dataset/Trai...     10\n",
       "51001  D:/BaiduNetdiskDownload/UAV_Fault_Dataset/Trai...      8\n",
       "...                                                  ...    ...\n",
       "8017   D:/BaiduNetdiskDownload/UAV_Fault_Dataset/Trai...      0\n",
       "78923  D:/BaiduNetdiskDownload/UAV_Fault_Dataset/Trai...     14\n",
       "92065  D:/BaiduNetdiskDownload/UAV_Fault_Dataset/Trai...     16\n",
       "23442  D:/BaiduNetdiskDownload/UAV_Fault_Dataset/Trai...      4\n",
       "43034  D:/BaiduNetdiskDownload/UAV_Fault_Dataset/Trai...      8\n",
       "\n",
       "[76175 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.data_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                            batch_size=50,\n",
    "                                            shuffle=True,\n",
    "                                            pin_memory=True,\n",
    "                                            num_workers=2,\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'BatchSampler' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_sampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'BatchSampler' object is not callable"
     ]
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steop:0, batch_x:tensor([[ 6.7986e-02,  1.5764e-01,  1.2074e-01,  ...,  1.5436e-01,\n",
      "          3.8256e-02,  3.3566e-02],\n",
      "        [-1.6771e-01, -1.1446e-01, -1.6113e-01,  ..., -1.3407e-02,\n",
      "         -8.7245e-02, -6.0785e-04],\n",
      "        [ 1.4448e-01,  1.8626e-01,  2.0455e-01,  ...,  7.8439e-03,\n",
      "          2.4354e-04,  8.1494e-02],\n",
      "        ...,\n",
      "        [ 2.5075e-01,  2.1021e-01,  2.9214e-01,  ..., -2.8464e-01,\n",
      "         -2.2513e-01, -3.4164e-01],\n",
      "        [-4.8891e-01, -5.1333e-01, -6.0393e-01,  ..., -2.9323e-01,\n",
      "         -2.1014e-01, -2.0760e-01],\n",
      "        [ 2.7761e-02,  7.0255e-02,  5.5642e-02,  ...,  1.4704e-01,\n",
      "          1.2047e-01,  1.1212e-01]]), batch_y:tensor([ 0,  0,  2, 12,  4, 16,  8, 10,  4,  4, 14, 16,  6, 12,  2,  8,  2,  4,\n",
      "         6,  6, 12, 16, 16,  2,  0,  6, 10,  6, 16,  0,  2, 14, 14, 10, 16, 14,\n",
      "        10,  0, 16, 16,  0, 16, 16, 10,  4, 16,  4,  2,  8, 16])\n",
      "steop:1, batch_x:tensor([[ 0.3636,  0.2075,  0.2173,  ..., -0.2752, -0.2870, -0.2920],\n",
      "        [-0.5920, -0.4182, -0.5130,  ..., -0.0744, -0.1122, -0.0386],\n",
      "        [ 0.2361,  0.2524,  0.1479,  ...,  0.2353,  0.2451,  0.1173],\n",
      "        ...,\n",
      "        [ 0.3385,  0.3214,  0.2049,  ..., -0.1394, -0.1167, -0.1398],\n",
      "        [-0.1261, -0.1580, -0.1576,  ...,  0.0702,  0.0756,  0.0310],\n",
      "        [-0.2992, -0.3512, -0.3734,  ...,  0.3438,  0.2389,  0.2801]]), batch_y:tensor([ 8, 14,  6, 12,  6,  0,  2,  6,  0,  2, 14, 12,  6, 10,  6,  0,  2, 12,\n",
      "         0,  2, 16,  2,  8,  8, 16, 16,  4, 12, 10, 12,  2,  8, 16,  2,  8, 12,\n",
      "        10,  2,  4, 12,  8,  0,  8,  4,  4, 12,  6,  0, 16,  4])\n",
      "steop:2, batch_x:tensor([[-0.3542, -0.1640, -0.3983,  ...,  0.2009,  0.3363,  0.2145],\n",
      "        [ 0.0235,  0.0644,  0.0302,  ...,  0.0557,  0.1548,  0.1587],\n",
      "        [-0.1733, -0.3265, -0.3349,  ..., -0.6592, -0.6376, -0.7413],\n",
      "        ...,\n",
      "        [-0.1805, -0.1690, -0.1991,  ..., -0.0142, -0.0453, -0.0282],\n",
      "        [ 0.3086,  0.2967,  0.2504,  ..., -0.2127, -0.2826, -0.2596],\n",
      "        [-0.4783, -0.2804, -0.3337,  ..., -0.0134,  0.0838,  0.0427]]), batch_y:tensor([ 4,  8,  6, 12, 10,  6, 16, 16, 16,  4,  6, 16,  4,  0, 12,  4, 14,  6,\n",
      "         0,  6,  8,  0, 12,  4,  2,  4, 16, 12, 12, 16,  2,  6,  4, 10, 16,  2,\n",
      "         0, 10, 12, 10,  8,  4,  2, 14,  4,  8,  6,  0, 16,  4])\n",
      "steop:3, batch_x:tensor([[ 0.1173,  0.1023,  0.1655,  ...,  0.1042,  0.1260,  0.0983],\n",
      "        [-0.0511, -0.0186, -0.0431,  ...,  0.0926,  0.0995,  0.0779],\n",
      "        [ 0.3094,  0.3167,  0.3488,  ..., -0.0258, -0.0304,  0.0246],\n",
      "        ...,\n",
      "        [-0.0712, -0.0283, -0.0886,  ..., -0.1720, -0.1423, -0.0765],\n",
      "        [ 0.2373,  0.3685,  0.3549,  ...,  0.4362,  0.3793,  0.4482],\n",
      "        [ 0.0866,  0.0884,  0.0021,  ..., -0.0623, -0.0068, -0.0373]]), batch_y:tensor([16,  6, 14, 14,  6,  8,  4, 12,  0, 14,  2, 16, 14, 10, 10,  4, 10, 16,\n",
      "        16, 14, 14, 12, 10, 10, 14,  8,  6, 12, 10,  2, 12, 16, 14, 16, 12, 14,\n",
      "         8,  2,  6,  4,  0, 10,  6, 10,  2,  8,  8, 16,  0,  0])\n",
      "steop:4, batch_x:tensor([[-0.2486, -0.2722, -0.3384,  ...,  0.1930,  0.1615,  0.1751],\n",
      "        [-0.2044,  0.0236,  0.0019,  ...,  0.1612,  0.2149,  0.1554],\n",
      "        [ 0.0087, -0.0256, -0.0720,  ...,  0.1746,  0.1567,  0.1289],\n",
      "        ...,\n",
      "        [ 0.1760,  0.3059,  0.1627,  ..., -0.0319,  0.1053,  0.1117],\n",
      "        [-0.0509, -0.0386,  0.0272,  ..., -0.1062, -0.1262, -0.1453],\n",
      "        [ 0.2866,  0.2108,  0.1291,  ...,  0.0417,  0.1548,  0.2673]]), batch_y:tensor([ 2, 12,  2,  4, 10,  8,  6, 14,  2,  0, 10, 12,  2, 16, 14, 14,  6,  0,\n",
      "        14, 10,  4, 16,  6,  6,  0, 14, 12,  2, 14, 10,  4,  0, 14, 16,  6, 10,\n",
      "         6,  0, 16,  0, 14, 12, 12, 12, 12,  2, 10,  6, 16,  2])\n",
      "steop:5, batch_x:tensor([[ 0.1055,  0.1085,  0.2855,  ...,  0.0398,  0.0692,  0.0423],\n",
      "        [ 0.0657,  0.0771,  0.1077,  ...,  0.1075,  0.2094,  0.2307],\n",
      "        [ 0.2090,  0.1691,  0.1369,  ..., -0.1200, -0.1599, -0.1822],\n",
      "        ...,\n",
      "        [ 0.0292,  0.0676, -0.0251,  ...,  0.0149,  0.0123, -0.0031],\n",
      "        [-0.2453, -0.3008, -0.3495,  ..., -0.1929, -0.2177, -0.2263],\n",
      "        [-0.1961, -0.1969, -0.2128,  ...,  0.1856,  0.1421,  0.1222]]), batch_y:tensor([12,  8, 14, 14,  2,  6, 14, 10, 16,  4, 16, 16,  0,  8,  0, 10,  0,  6,\n",
      "         0,  6,  0,  6, 12, 12,  2, 10, 10,  4,  2,  0,  4, 12, 12,  2,  2, 16,\n",
      "        12,  6,  4,  6,  0,  2,  0,  6, 12, 12,  0, 16,  6, 14])\n",
      "steop:6, batch_x:tensor([[ 0.2055,  0.1257,  0.0459,  ..., -0.0616, -0.0656, -0.0875],\n",
      "        [ 0.0849,  0.1725,  0.1610,  ..., -0.2661, -0.2395, -0.2978],\n",
      "        [-0.5540, -0.3674, -0.1698,  ..., -0.0596, -0.0959, -0.1086],\n",
      "        ...,\n",
      "        [ 0.0893,  0.0349,  0.0078,  ...,  0.0923,  0.1110,  0.0541],\n",
      "        [-0.2031, -0.2295, -0.2531,  ...,  0.3252,  0.3390,  0.2928],\n",
      "        [-0.1882, -0.1161, -0.0674,  ..., -0.1392, -0.1275, -0.0979]]), batch_y:tensor([ 4, 10,  8, 16,  8, 16, 16,  2, 12, 16,  6,  4, 14, 14, 14,  8, 10,  8,\n",
      "        14,  4, 10,  0, 10,  4, 12,  2,  2,  4,  0, 14,  6, 12, 12,  0, 14,  6,\n",
      "        16,  8, 10,  0, 12, 10, 14, 14, 10,  6, 12,  2, 12,  0])\n",
      "steop:7, batch_x:tensor([[-0.1047,  0.0141,  0.0526,  ..., -0.2002, -0.2238, -0.2261],\n",
      "        [ 0.0662,  0.1037,  0.1197,  ..., -0.0295, -0.0198, -0.0552],\n",
      "        [-0.2237, -0.0613,  0.0506,  ...,  0.0973,  0.0914,  0.0991],\n",
      "        ...,\n",
      "        [ 0.4191,  0.4296,  0.3841,  ...,  0.3526,  0.3524,  0.3543],\n",
      "        [ 0.3248,  0.3442,  0.3344,  ..., -0.0397, -0.1862, -0.1453],\n",
      "        [ 0.3769,  0.3550,  0.3242,  ..., -0.0662, -0.0828, -0.0816]]), batch_y:tensor([ 4,  8, 14,  8,  8,  4,  4,  6,  0,  8,  2,  8,  4, 14, 16,  8,  4, 16,\n",
      "         6,  4, 10,  2,  8,  8,  6,  0,  4, 12,  4, 12, 16, 12,  4, 10, 16,  8,\n",
      "         8, 16, 12, 14,  2,  0, 14,  4, 16, 14,  0, 14, 16,  8])\n",
      "steop:8, batch_x:tensor([[ 0.2935,  0.2760,  0.1792,  ..., -0.3067, -0.2969, -0.2286],\n",
      "        [ 0.2936,  0.2497,  0.3028,  ...,  0.2020,  0.2404,  0.2503],\n",
      "        [-0.3150, -0.2527, -0.3188,  ..., -0.0790, -0.0771, -0.1059],\n",
      "        ...,\n",
      "        [ 0.1147,  0.0514,  0.0643,  ..., -0.1206, -0.0918, -0.0863],\n",
      "        [-0.0318,  0.0121, -0.0791,  ...,  0.5627,  0.5784,  0.4930],\n",
      "        [-0.2116, -0.2330, -0.2738,  ...,  0.0342,  0.0963, -0.0362]]), batch_y:tensor([ 2,  4, 16,  4,  0,  8,  8, 10,  8,  2, 10,  6, 16, 12, 16,  0,  4, 16,\n",
      "         0, 12, 14, 14,  6,  0, 16, 12,  2, 16,  8, 14,  6,  2, 12,  8,  4,  6,\n",
      "        10,  2,  8, 12, 16, 14, 16, 12, 14,  4,  4, 12, 12,  8])\n"
     ]
    },
    {
     "ename": "MatReadError",
     "evalue": "Caught MatReadError in DataLoader worker process 1.\nOriginal Traceback (most recent call last):\n  File \"d:\\Program\\Anaconda\\envs\\DL\\lib\\site-packages\\hdf5storage\\__init__.py\", line 1777, in loadmat\n    with h5py.File(filename, mode='r') as f:\n  File \"d:\\Program\\Anaconda\\envs\\DL\\lib\\site-packages\\h5py\\_hl\\files.py\", line 562, in __init__\n    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)\n  File \"d:\\Program\\Anaconda\\envs\\DL\\lib\\site-packages\\h5py\\_hl\\files.py\", line 235, in make_fid\n    fid = h5f.open(name, flags, fapl=fapl)\n  File \"h5py\\_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n  File \"h5py\\_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n  File \"h5py\\h5f.pyx\", line 102, in h5py.h5f.open\nFileNotFoundError: [Errno 2] Unable to synchronously open file (unable to open file: name = 'D:/BaiduNetdiskDownload/UAV_Fault_Dataset/Train\\MF1\\MF1_330.mat.baiduyun.downloading.cfg.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"d:\\Program\\Anaconda\\envs\\DL\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"d:\\Program\\Anaconda\\envs\\DL\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"d:\\Program\\Anaconda\\envs\\DL\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"d:\\Learn\\deep-learning-for-image-processing-master\\pytorch_classification\\swin_transformer\\data_set.py\", line 17, in __getitem__\n    data = hdf5storage.loadmat(file_path)['single_data']#提取数据并转置\n  File \"d:\\Program\\Anaconda\\envs\\DL\\lib\\site-packages\\hdf5storage\\__init__.py\", line 1811, in loadmat\n    return scipy.io.loadmat(file_name, mdict, appendmat=appendmat,\n  File \"d:\\Program\\Anaconda\\envs\\DL\\lib\\site-packages\\scipy\\io\\matlab\\_mio.py\", line 226, in loadmat\n    MR, _ = mat_reader_factory(f, **kwargs)\n  File \"d:\\Program\\Anaconda\\envs\\DL\\lib\\site-packages\\scipy\\io\\matlab\\_mio.py\", line 74, in mat_reader_factory\n    mjv, mnv = _get_matfile_version(byte_stream)\n  File \"d:\\Program\\Anaconda\\envs\\DL\\lib\\site-packages\\scipy\\io\\matlab\\_miobase.py\", line 232, in _get_matfile_version\n    raise MatReadError(\"Mat file appears to be empty\")\nscipy.io.matlab._miobase.MatReadError: Mat file appears to be empty\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMatReadError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m step, (batch_x, batch_y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m      3\u001b[0m             \u001b[38;5;66;03m# training\u001b[39;00m\n\u001b[0;32m      4\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msteop:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, batch_x:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, batch_y:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(step, batch_x, batch_y))\n",
      "File \u001b[1;32md:\\Program\\Anaconda\\envs\\DL\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    650\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 652\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    656\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32md:\\Program\\Anaconda\\envs\\DL\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1347\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1346\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[1;32m-> 1347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Program\\Anaconda\\envs\\DL\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1373\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[0;32m   1372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[1;32m-> 1373\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32md:\\Program\\Anaconda\\envs\\DL\\lib\\site-packages\\torch\\_utils.py:461\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 461\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[1;31mMatReadError\u001b[0m: Caught MatReadError in DataLoader worker process 1.\nOriginal Traceback (most recent call last):\n  File \"d:\\Program\\Anaconda\\envs\\DL\\lib\\site-packages\\hdf5storage\\__init__.py\", line 1777, in loadmat\n    with h5py.File(filename, mode='r') as f:\n  File \"d:\\Program\\Anaconda\\envs\\DL\\lib\\site-packages\\h5py\\_hl\\files.py\", line 562, in __init__\n    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)\n  File \"d:\\Program\\Anaconda\\envs\\DL\\lib\\site-packages\\h5py\\_hl\\files.py\", line 235, in make_fid\n    fid = h5f.open(name, flags, fapl=fapl)\n  File \"h5py\\_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n  File \"h5py\\_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n  File \"h5py\\h5f.pyx\", line 102, in h5py.h5f.open\nFileNotFoundError: [Errno 2] Unable to synchronously open file (unable to open file: name = 'D:/BaiduNetdiskDownload/UAV_Fault_Dataset/Train\\MF1\\MF1_330.mat.baiduyun.downloading.cfg.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"d:\\Program\\Anaconda\\envs\\DL\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"d:\\Program\\Anaconda\\envs\\DL\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"d:\\Program\\Anaconda\\envs\\DL\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"d:\\Learn\\deep-learning-for-image-processing-master\\pytorch_classification\\swin_transformer\\data_set.py\", line 17, in __getitem__\n    data = hdf5storage.loadmat(file_path)['single_data']#提取数据并转置\n  File \"d:\\Program\\Anaconda\\envs\\DL\\lib\\site-packages\\hdf5storage\\__init__.py\", line 1811, in loadmat\n    return scipy.io.loadmat(file_name, mdict, appendmat=appendmat,\n  File \"d:\\Program\\Anaconda\\envs\\DL\\lib\\site-packages\\scipy\\io\\matlab\\_mio.py\", line 226, in loadmat\n    MR, _ = mat_reader_factory(f, **kwargs)\n  File \"d:\\Program\\Anaconda\\envs\\DL\\lib\\site-packages\\scipy\\io\\matlab\\_mio.py\", line 74, in mat_reader_factory\n    mjv, mnv = _get_matfile_version(byte_stream)\n  File \"d:\\Program\\Anaconda\\envs\\DL\\lib\\site-packages\\scipy\\io\\matlab\\_miobase.py\", line 232, in _get_matfile_version\n    raise MatReadError(\"Mat file appears to be empty\")\nscipy.io.matlab._miobase.MatReadError: Mat file appears to be empty\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "        for step, (batch_x, batch_y) in enumerate(train_loader):\n",
    "            # training\n",
    "            print(\"steop:{}, batch_x:{}, batch_y:{}\".format(step, batch_x, batch_y))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
